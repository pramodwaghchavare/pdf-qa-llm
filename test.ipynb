{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cbd1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 1. Import Libraries\n",
    "# -------------------------\n",
    "import os\n",
    "import langchain\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone as LangChainPinecone\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from pinecone import Pinecone, ServerlessSpec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4dde69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9bb363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# 2. Load Environment Keys\n",
    "# -------------------------\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCH_aOk-es_8ceS-3ZdEgcMZY_FgSvjJAs\"   # Or keep in .env\n",
    "pc = Pinecone(api_key=\"pcsk_5Um72N_4DWGGx6E8B2PM4g8mVSAZ5NuWzE9b8e15cqHSYbqw8V8t9Rzm8SfPRp2Ff3oGzK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c662b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4383bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# 3. Read PDF Documents\n",
    "# -------------------------\n",
    "def read_doc(directory):\n",
    "    file_loader = PyPDFDirectoryLoader(directory)\n",
    "    documents = file_loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6650d216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = read_doc(\"documents/\")\n",
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0812e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------\n",
    "# 4. Chunk Documents\n",
    "# -------------------------\n",
    "def chunk_data(docs, chunk_size=800, chunk_overlap=50):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc07faef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = chunk_data(doc)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "734bdb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 768\n"
     ]
    }
   ],
   "source": [
    "# 5. Gemini Embeddings\n",
    "# -------------------------\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "vectors = embeddings.embed_query(\"How are you?\")\n",
    "print(\"Embedding length:\", len(vectors))  # should be 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f108921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pramod\\Desktop\\LLMAPP\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 6. Pinecone Setup (v3 style)\n",
    "# -------------------------\n",
    "index_name = \"langchainvector\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,   # Gemini embeddings size\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\") # pick valid region\n",
    "    )\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adfd79cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20f93153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Retrieve Similar Docs\n",
    "# # -------------------------\n",
    "def retrieve_query(query, k=2):\n",
    "    return vectorstore.similarity_search(query, k=k)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd5b5f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. QA Chain with Gemini\n",
    "# -------------------------\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.5)\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2441698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 10. Ask Question\n",
    "# -------------------------\n",
    "def retrieve_answers(query):\n",
    "    doc_search = retrieve_query(query)\n",
    "    print(\"Matched docs:\", doc_search[:1])  # preview first doc\n",
    "    response = chain.run(input_documents=doc_search, question=query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f66093fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched docs: [Document(id='1f4dd2b7-816b-4ee1-9ac7-641d677f0172', metadata={'creationdate': '2023-02-01T05:28:04+05:30', 'creator': 'Adobe Acrobat Pro 10.1.16', 'moddate': '2023-02-01T08:28:21+05:30', 'page': 31.0, 'page_label': '32', 'producer': 'Adobe Acrobat Pro 10.1.16', 'source': 'documents\\\\budget_speech (1).pdf', 'title': '', 'total_pages': 58.0}, page_content='contributing about three-fourths of the global turnover by value. With the \\ndepletion in deposits of natural diamonds, the industry is moving towards \\nLab Grown Diamonds (LGDs) and it holds huge promise. To seize this')]\n",
      "\n",
      "Gemini Answer: This document does not contain any information about \"Green growth\".\n"
     ]
    }
   ],
   "source": [
    "\n",
    "our_query = \"What is Green growth?\"\n",
    "answer = retrieve_answers(our_query)\n",
    "print(\"\\nGemini Answer:\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
